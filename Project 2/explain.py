import numpy as np
import re
import interface
import psycopg2
import itertools
from typing import TypedDict, List


class LoginDetails(TypedDict):
    host: str
    port: int
    user: str
    password: str


class QueryDetails(TypedDict):
    database: str
    query: str


class DatabaseConnector(object):
    def __init__(self, login_details: LoginDetails, databasename=None):
        self.connector = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        ).cursor()

    def __enter__(self):
        return self.connector

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.connector.close()


def check_connection(login_details: LoginDetails, databasename=None):
    """
    Attempts to connect to a PostgreSQL database and returns True if successful.

    :param login_details: An instance of LoginDetails containing connection parameters.
    :param databasename: Optional. The name of the database to connect to.
    :return: True if the connection is successful, False otherwise.
    """
    try:
        # Connect to the database (or just the server if databasename is None)
        conn = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        )

        # If the connection was successful, close it and return True
        conn.close()
        return True
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error("Connection to DB Failed\n" + str(e))
        return False


def get_database_names(login_details: LoginDetails) -> List[str]:
    try:
        with DatabaseConnector(login_details) as cursor:
            query = "SELECT datname FROM pg_database WHERE datistemplate = false;"
            cursor.execute(query)
            database_list = cursor.fetchall()
            database_list = [i[0] for i in database_list]
            return database_list
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error(str(e))


def retrieve_query(login_details: LoginDetails, querydetails: QueryDetails, explain = True):
    with DatabaseConnector(login_details, querydetails.database) as cursor:
        if explain:
            query = f"EXPLAIN (FORMAT JSON) {str(querydetails.query)}"
        else:
            query = str(querydetails.query)
        
        try:
            print(querydetails.query.strip())
            cursor.execute(query)
            query_data = cursor.fetchall()
            print(query_data)
            return query_data
        except:
            return None


def load_qep_explanations(plan_json, login_details, query_details):
    # Build a query tree
    tree = Tree(login_details, query_details)
    tree.build_tree(plan_json)

    # Explain each node by DFS and return the output
    return tree.dfs_explain_all(tree.root).strip()

import json

class Tree(object):
    """
    Represents a Query Tree generated by PostgreSQL's JSON output

    This tree is binary. If there is only one child, the child node will
    be assigned to the left child.
    """

    def __init__(self, login_details, query_details):
        # Root node of the tree
        self.root = None

        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # The output string for the entire query tree that will be printed on the interface
        self.full_output = ""

        # Keeps track at tree-level the value of n
        # for the n-th node that is currently being processed
        self.order = 1

    def build_tree(self, node_json):
        # Recursively build the binary tree from JSON data
        # Data given to build_tree is the value of the key "Plan"

        self.root = self._build_tree_recursive(node_json)

    def _build_tree_recursive(self, node_json):
         # Recursively build the binary tree from node data
        if not node_json:
            return None

        node = self.create_node(node_json)
            
        # Continue running this function only if there are child nodes
        if node is not None and "Plans" in node.node_json:
            plans = node.node_json["Plans"]
            if len(plans) == 1:
                node.left = self._build_tree_recursive(plans[0])
            elif len(plans) == 2:
                node.left = self._build_tree_recursive(plans[0])
                node.right = self._build_tree_recursive(plans[1])

            # node.node_json["Plans"] no longer needed, empty it
            node.node_json["Plans"] = {}

        return node

    def dfs_explain_all(self, node):
        # Function to perform depth-first traversal of the binary tree
        if node is not None:
            self.dfs_explain_all(node.left)
            self.dfs_explain_all(node.right)
            
            # After calling explain() on both child nodes
            # Merge their parent_dict before processing current node
            node.merge_dict()

            # Append the explanation of the node to the full string
            # And add separators to distinguish between different nodes
            self.full_output = self.full_output + node.explain(self.order) + '\n'
            if node is not self.root:
                self.full_output = self.full_output + "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n"
            
            # Increment current node order
            self.order += 1

        return self.full_output


    def create_node(self, node_json):
        match node_json["Node Type"]:
            case "Seq Scan": 
                return SeqScanNode(node_json, self.login_details, self.query_details)
            case _: 
                return Node(node_json, self.login_details, self.query_details)

class Node(object):
    """
    Represents a Node in PostgreSQL's EXPLAIN JSON output

    All nodes should inherit from this class.
    The subclasses should also replace the following attributes
    and functions with their own implementations:
    - __init__(self) to replace str_explain_formula and str_explain_difference
    - manual_cost(node_json)
    """

    def __init__(self, node_json, login_details, query_details):
        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # Given formula or how formula is derived
        self.str_explain_formula = "str_explain_formula"

        # Brief explanation on the difference between formula and system calculations
        self.str_explain_difference = "str_explain_difference"

        # The JSON of this particular node
        self.node_json = node_json

        # Left and right child Node
        self.left = None
        self.right = None

        # The entire output string that will be printed by the interface.
        # This variable should ONLY be modified between when explain() is triggered
        # and when explain() is returned
        self.output = ""

        # Dict data structure to pass to parent
        self.parent_dict = None

    def manual_cost(self):
        """
        Run the SQL helper functions here.
        Each SQL helper function will also append a line to the output
        This method will return the total manually calculated cost.

        @returns: An integer for the manually calculated total cost
        """
        return 0

    def explain(self, order = 0):
        """
        Prepares the output for the particular node to be printed by the interface.
        Also handles clean-up after explain() is executed successfully

        @type order : int
        @param order : The order in which this Node is being explained, relative
                       to the entire query tree
        """

        # Reset the output just in case
        self.output = ""

        # Briefly introduce the node with the name of the Node Type
        self.append(str(order) + ". " + self.node_json["Node Type"])
        self.append()

        # Append the formula explanation
        self.append(self.str_explain_formula)
        calculated_cost = self.manual_cost()

        # Append the calculated cost
        self.append("Calculated Cost: " + str(calculated_cost))
        self.append()

        # Append the PostgreSQL total cost
        self.append("PostgreSQL Total Cost: " + str(self.node_json.get("Total Cost", "Unknown")))

        # Compare the calculated cost with PostgreSQL's total cost
        if calculated_cost == self.node_json.get("Total Cost"):
            self.append("Manually calculated cost is the same as system calculated cost.")
        else:
            self.append("Manually calculated cost is different from system calculated cost.")
            self.append()
            self.append("Reason for difference:")
            self.append(self.str_explain_difference)

        # This node has been explained once
        # Build a dict to pass to parent to mark this Node as explained
        self.parent_dict = self.build_parent_dict() 

        return self.output

    def build_parent_dict(self):
        """
        Builds a dict of specific values to pass to the parent Node for their
        calculations. Only includes necessary attributes.
        """
        attributes = ["Node Type", "block_size", "tuple_size", "manual_cost", "postgre_cost"]
        return {attr: self.node_json[attr] for attr in attributes if attr in self.node_json}
    
        # return self.node_json.copy()

    def merge_dict(self):
        """
        Obtains the dictionary created by the left and right childs if any
        Then, label the dict to each child, and merge the two dictionaries
        with the JSON provided by PostgreSQL into one big dictionary.
        """
        if self.left is not None:
            for key, value in self.left.parent_dict.items():
                self.node_json["Left " + key] = value
        if self.right is not None:
            for key, value in self.right.parent_dict.items():
                self.node_json["Right " + key] = value

    def append(self, tgt_str = "", src_str = "output", eol = '\n'):
        '''
        Append a string to the end of the selected string.
        If no src_str is specified, then append to Node.output
        If no tgt_str is specified, then the behaviour is similar to print(),
        which is to add an empty line to the output
        If no eol is specified, a newline character will be added after each string.
        '''
        match src_str:
            case "formula":
                self.str_explain_formula = self.str_explain_formula + str(tgt_str) + eol
            case "difference":
                self.str_explain_difference = self.str_explain_difference + str(tgt_str) + eol
            case _:
                self.output = self.output + str(tgt_str) + eol

    ######### Functions that Re-queries the Database #########

    def B(self, relation, show = True):
        """
        Return number of blocks for the specified relation

        @type show : boolean
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT pg_relation_size('{rel}') / current_setting('block_size')::int AS num_blocks
        '''.format(rel = relation)

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_blocks = result[0][0]

# SELECT pg_relation_size({rel}) / current_setting('block_size')::int AS total_blocks
# FROM pg_class
# WHERE relname = {rel};

        if show: 
            self.append("Number of blocks for relation '" + relation + "': " + str(num_blocks))
        return num_blocks

    def T(self, relation, show = True):
        """
        Return number of tuples for the specified relation

        @type show : boolean
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT COUNT(*) as num_tuples FROM {rel}
        '''.format(rel = relation)

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_tuples = result[0][0]

        if show: 
            self.append("Number of tuples for relation '" + relation + "': " + str(num_tuples))
        return num_tuples

    def M(self, show = True):
        """
        Return buffer size allocated to DBMS in memory

        @type show : boolean
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT setting FROM pg_settings WHERE name = 'shared_buffers';
        '''

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        buffer_size = int(result[0][0])

        if show: 
            self.append("Buffer size: " + str(buffer_size))
        return buffer_size

    def V(self, relation, attribute, show = True):
        """
        Return number of unique values for the attribute in
        the provided relation

        @type show : boolean
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT COUNT(DISTINCT {attr}) AS num_unique_values FROM {rel};
        '''.format(attr = attribute, rel = relation)

# SELECT n_distinct
# FROM pg_stats
# WHERE tablename = 'relation_name' AND attname = 'attribute_name';

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_unique = result[0][0]

        if show: 
            self.append(
                "Number of unique values for attribute '" +
                attribute +
                "' of relation '" +
                relation +
                "': " +
                str(num_unique)
            )
        return num_unique


#################### NODE SUBCLASSES ######################


class MyScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "Formula: B(rel) + T(rel) + V(rel, attr) + M"
        self.str_explain_difference = "Some explanation for difference"

    def manual_cost(self):
        rel = "nation"
        attr = "n_name"
        return self.B(rel) + self.T(rel) + self.V(rel, attr) + self.M()

class SeqScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Three different cases
        if "Filter" not in self.node_json:
            # Case 1: Retrieve entire table. Selectivity = 1
            self.str_explain_formula = '''Retrieving the entire table. Selectivity = 1
            Cost Formula: B({rel})
            '''.format(rel = self.node_json["Relation Name"])
            self.str_explain_difference = '''PostgreSQL factors in parallel processing and CPU cost into the calculation
            '''

            # Explain the difference
            self.str_explain_difference = '''PostgreSQL factors in parallel processing and CPU cost into the calculation
            '''

        elif '>' in self.node_json["Filter"] or '<' in self.node_json["Filter"]:
            # Case 2: Retrieve a range of records. Selectivity = 1/3
            self.str_explain_formula = '''Finding range of values. Selectivity = 1/3
            Cost Formula: B({rel}) / 3)
            '''.format(rel = self.node_json["Relation Name"])
            self.str_explain_difference = '''PostgreSQL estimates the selectivity more accurately.
            PostgreSQL factors in parallel processing and CPU cost into the calculation
            '''

            # Explain the difference
            self.str_explain_difference = '''PostgreSQL estimates the selectivity more accurately.
            PostgreSQL factors in parallel processing and CPU cost into the calculation
            '''

        else:
            # Case 3: Retrieve one exact record. Selectivity = V(R, a)

            # Explain the relation, attribute 
            rel = self.node_json["Relation Name"]
            attr = SeqScanNode.retrieve_attribute_from_filter(self.node_json["Filter"])
            self.str_explain_formula = '''Finding exact match of value. Selectivity = Number of unique values
            Cost Formula: B({rel}) / V({rel}, {attr})
            '''.format(rel = rel, attr = attr)

            # Explain the difference
            self.str_explain_difference = '''PostgreSQL estimates the selectivity more accurately.
            PostgreSQL factors in parallel processing and CPU cost into the calculation
            '''

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = SeqScanNode.retrieve_attribute_from_filter(self.node_json["Filter"])
        
        # Three different cases
        if "Filter" not in self.node_json:
            # Case 1: Retrieve entire table. Selectivity = 1
            return self.B(rel)

        elif '>' in self.node_json["Filter"] or '<' in self.node_json["Filter"]:
            # Case 2: Retrieve a range of records. Selectivity = 1/3
            return self.B(rel) / 3

        else:
            # Case 3: Retrieve one exact record. Selectivity = V(R, a)
            if self.V(rel, attr) == 0:
                return self.B(rel)
            return self.B(rel) / self.V(rel, attr)       
    
    def retrieve_attribute_from_filter(filter):
        '''
        Pass in the value from node_json["Filter"] and return the attribute
        Example filter = "(o_custkey < 1000000)"
        '''

        # Define the comparison operators
        comparison_operators = ['<', '>', '=']

        # Find the index of the first appearance of any comparison operator
        index = min(filter.find(op) for op in comparison_operators if op in filter)

        # Extract the text before the comparison operator
        attr = filter[1:index].strip()

        return attr


class IndexScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)


        # Explain the relation, attribute
        rel = self.node_json["Relation"]
        attr = self.node_json["Attribute"]
        args = {"attr": attr, "rel": rel}
        self.str_explain_formula = """Index on attribute '{attr}' of relation '{rel}'
        Cost Formula: T({rel}) / V({rel}, {attr})
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """PostgreSQL uses the more accurate Market and Lohman approximation to estimate number of pages fetched.
        Also, PostgreSQL uses optimizations such as  parallel processing and caching.
        These will either reduce cost or makes cost computation more accurate.
        """

    def manual_cost(self):
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        return self.T(rel) / self.V(attr, rel)

class IndexOnlyScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute 
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        args = {'attr': attr, 'rel': rel}
        self.str_explain_formula = '''Index on attribute '{attr}' of relation '{rel}'
        Cost Formula: T({rel}) / V({rel}, {attr})
        '''.format(attr = self.node_json["Filter"], rel =self.node_json["Node Type"])

        # Explain the difference
        self.str_explain_difference = '''Index Only Scan differs from Index Scan in that PostgreSQL only needs to access the index blocks as all of the values required are in the index.
        PostgreSQL uses methods to reduce the cost as a result of not requiring to access heap storage.
        '''

    def manual_cost(self):
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        return self.T(rel) / self.V(attr, rel)

class BitmapIndexScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute 
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        args = {'attr': attr, 'rel': rel}
        self.str_explain_formula = '''Index on attribute '{attr}' of relation '{rel}'
        Cost Formula: T({rel}) / V({rel}, {attr})
        '''.format(args)

        # Explain the difference
        self.str_explain_difference = '''Bitmap Index Scan does not access the heap.
        Also, PostgreSQL considers other factors such as bitmap initialization into its cost calculation
        '''

    def manual_cost(self):
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        return self.T(rel) / self.V(attr, rel)

class BitmapHeapScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute 
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        args = {'attr': attr, 'rel': rel}
        self.str_explain_formula = '''Index on attribute '{attr}' of relation '{rel}'
        Cost Formula: T({rel}) / V({rel}, {attr})
        '''.format(args)

        # Explain the difference
        self.str_explain_difference = '''PostgreSQL factors in overhead of bitmap access into cost calculation
        '''

    def manual_cost(self):
        rel = self.node_json["Node Type"]
        attr = self.node_json["Filter"]
        return self.T(rel) / self.V(attr, rel)

class BitmapAndNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "AND operation on bit arrays are negligible"
        self.str_explain_difference = '''PostgreSQL factors in overhead of bitmap access into cost calculation
        '''

    def manual_cost(self):
        return 0

class BitmapOrNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "OR operation on bit arrays are negligible"
        self.str_explain_difference = '''PostgreSQL factors in overhead of bitmap access into cost calculation
        '''

    def manual_cost(self):
        return 0

class CTEScanNode(SeqScanNode):
    '''
    CTE Scan is very similar to sequential scan, but for WITH operations
    '''
    pass

class AppendNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combine the results of the child operations.
        Cost Formula: SIGMA(Cost(Child))
        """

        # Explain the difference
        self.str_explain_difference = """PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions.
        """

    def manual_cost(self):
        
        total_cost = self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        
        return total_cost


class MergeAppendNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the sorted results of the child operations, in a way that preserves their sort order.
        Cost Formula: SIGMA(Cost(Child)) + Merge_Cost
        """

        # Explain the difference
        self.str_explain_difference = """MergeAppend of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream.  If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top entry.
        """

    def manual_cost(self):
        total_cost = (
            self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        )

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = self.node_json["Left tuple_size"] + self.node_json["Right tuple_size"]
        total_cost += merge_cost

        return total_cost


class NestedLoopJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """An implementation of join or lookup where the first child node is run once, then for every row it produces, its partner is looked up in the second node.
        Cost Formula: min(B({R}), B({S})) + (B({R}) * B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """The cost estimation in PostgreSQL sums up the startup cost, total cost of both outer and inner path, and also the rescan cost of the inner path. However, the approach is different and not by using block size, but instead it takes the cost of the path.
        """

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return min(R_block_size, S_block_size) + (R_block_size * S_block_size)


class MergeJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """An implementation of join which is possible when the two lists of rows to be joined are already sorted on their join keys.
        Cost Formula: 3(B({R}) + B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """ PostgreSQL's cost estimation is more comprehensive, accounting for sorting costs, actual data size and distribution, and system factors like disk I/O, CPU usage, and caching effects, leading to a more accurate and context-sensitive prediction.
        """

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size + S_block_size)


class HashNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        rel = self.node_json["Left Node Type"]

        args = {"rel": rel}
        # self.str_explain_formula = """Hashes the query rows for use by its parent operation, usually used to perform a JOIN.'
        # Cost Formula: Total_Cost = Scan_Cost + Hash_Build_Cost (Assume T({rel}) here for now.)
        # """.format(
        #     args
        # )

        self.str_explain_formula = """Hashes the query rows for use by its parent operation, usually used to perform a JOIN.'
        We assume the cost are calculated in the hash join node, thus ignore the cost here.
        """

        # Explain the difference
        self.str_explain_difference = """We assume the cost are calculated in the hash join node, thus ignore the cost here. In PostgreSQL, the cost is calculated for the whole hash join process using two versions of estimation function, no separate calculation for hash nodes.
        """

    def manual_cost(self):

        # return self.node_json["Left tuple_size"]

        return 0


class HashJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """A hash join operation between two relations, where the first relation '{rel_R}' is used to build the hash table, and the second relation '{rel_S}' is then probed against this hash table.'
        Cost Formula: 3(B({R}) + B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """Our implementation here follows the Grace hash join calculation.
        PostgreSQL does not use the Grace hash join algorithm. 
        Instead, it implements a variant of the hash join that is optimized for in-memory operations but can also handle larger-than-memory datasets by spilling to disk.
        """

    def manual_cost(self):
        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size * S_block_size)


class GatherNode(Node): # formula unsure
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the output of child nodes, which are executed by parallel workers.
        Cost Formula: SIGMA(Cost(Child))
        """

        # Explain the difference
        self.str_explain_difference = """PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions. Parallel setup  and communication cost are also taken into consideration.
        """

    def manual_cost(self):
        total_cost = 0
        for child in self.node_json["ChildNodes"]:
            total_cost += child.manual_cost()
        return total_cost


class GatherMergeNode(Node): # formula unsure
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the output of child nodes, which are executed by parallel workers. Gather Merge consumes sorted data, and preserves this sort order.
        Cost Formula: SIGMA(Cost(Child)) + Merge_Cost
        """

        # Explain the difference
        self.str_explain_difference = """GatherMerge of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream. If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top heap entry with the next tuple from the same stream. Parallel setup  and communication cost are also taken into consideration.
        """

    def manual_cost(self):
        total_cost = (
            self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        )

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = (
            self.node_json["Left tuple_size"] + self.node_json["Right tuple_size"]
        )
        total_cost += merge_cost

        return total_cost


####################### CODE TO RUN ########################

# sample_json = {"Relation": "relA", "Attribute": "attrA", "Total Cost": 20}
# node = MyScanNode(json.dumps(sample_json))
# node.explain()


###################### testing ################################
import json
sample_qep = """
{
    "Node Type": "Seq Scan",
    "Parent Relationship": "Inner",
    "Parallel Aware": false,
    "Async Capable": false,
    "Relation Name": "nation",
    "Alias": "nation",
    "Startup Cost": 0.0,
    "Total Cost": 12.12,
    "Plan Rows": 1,
    "Plan Width": 434,
    "Filter": "(n_regionkey = 1)",
    "Plans": [
        {
            "Node Type": "Seq Scan",
            "Parent Relationship": "Inner",
            "Parallel Aware": false,
            "Async Capable": false,
            "Relation Name": "nation",
            "Alias": "nation",
            "Startup Cost": 0.0,
            "Total Cost": 12.12,
            "Plan Rows": 1,
            "Plan Width": 434,
            "Filter": "(n_regionkey = 1)"
        }
    ]
}

"""
# load_qep_explanations(json.loads(sample_qep))