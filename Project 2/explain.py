import numpy as np
import re
import interface
import psycopg2
import itertools
from typing import TypedDict, List


class LoginDetails(TypedDict):
    host: str
    port: int
    user: str
    password: str


class QueryDetails(TypedDict):
    database: str
    query: str


class DatabaseConnector(object):
    def __init__(self, login_details: LoginDetails, databasename=None):
        self.connector = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        ).cursor()

    def __enter__(self):
        return self.connector

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.connector.close()


def check_connection(login_details: LoginDetails, databasename=None):
    """
    Attempts to connect to a PostgreSQL database and returns True if successful.

    :param login_details: An instance of LoginDetails containing connection parameters.
    :param databasename: Optional. The name of the database to connect to.
    :return: True if the connection is successful, False otherwise.
    """
    try:
        # Connect to the database (or just the server if databasename is None)
        conn = psycopg2.connect(
            host=login_details.host,
            port=login_details.port,
            user=login_details.user,
            password=login_details.password,
            dbname=databasename if databasename else "",
        )

        # If the connection was successful, close it and return True
        conn.close()
        return True
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error("Connection to DB Failed\n" + str(e))
        return False


def get_database_names(login_details: LoginDetails) -> List[str]:
    try:
        with DatabaseConnector(login_details) as cursor:
            query = "SELECT datname FROM pg_database WHERE datistemplate = false;"
            cursor.execute(query)
            database_list = cursor.fetchall()
            database_list = [i[0] for i in database_list]
            return database_list
    except psycopg2.OperationalError as e:
        from project import Main

        Main.show_error(str(e))


def retrieve_query(login_details: LoginDetails, querydetails: QueryDetails, explain = True):
    with DatabaseConnector(login_details, querydetails.database) as cursor:
        if explain:
            query = f"EXPLAIN (ANALYZE, VERBOSE, FORMAT JSON) {str(querydetails.query)}"
        else:
            query = str(querydetails.query)
        
        try:
            print(querydetails.query.strip())
            cursor.execute(query)
            query_data = cursor.fetchall()
            print(query_data)
            return query_data
        except:
            return None


def load_qep_explanations(tree):
    return tree.explain_all_nodes(tree.root).strip()

def initialize_tree(plan_json, login_details, query_details):
    tree = Tree(login_details, query_details)
    tree.build_tree(plan_json)

    # Explain each node by DFS and return the output
    return tree


class Tree(object):
    """
    Represents a Query Tree generated by PostgreSQL's JSON output

    This tree is binary. If there is only one child, the child node will
    be assigned to the left child.

    @param login_details: User-provided login details to the UI
    @param query_details: Contains the user-selected database and user-input query
    """

    def __init__(self, login_details: LoginDetails, query_details: QueryDetails):
        # Root node of the tree
        self.root = None

        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # The output string for the entire query tree that will be printed on the interface
        self.full_output = ""

        # Keeps track at tree-level the value of n
        # for the n-th node that is currently being processed
        self.order = 1

    def build_tree(self, node_json):
        '''
        Recursively build the binary tree from JSON data
        Data given to build_tree is the value of the key "Plan"

        @param node_json: The JSON / dictionary of details specific to the node
        '''

        # Saves the root and begins recursively creating the tree
        self.root = self._build_tree_recursive(node_json)

    def _build_tree_recursive(self, node_json, count=[1]):
        """
        Helper function of self.Build_tree()

        Recursively build the binary tree from node data

        @param node_json: The JSON / dictionary of details specific to the node
        @param count: Mutable list which is by reference can maintain the state throughout mutable calls.
        @return: The instantiated node
        """

        # Default case - Previous node is already a leaf node
        if not node_json:
            return None

        # Instantiate a Node subclass
        node = self.instantiate_node(node_json)

        if node:
            node.id = count[0]  # Assign the current count as the node number
            count[0] += 1  # Increment the count for the next node

        # Continue running this function only if there are child nodes
        if node is not None and "Plans" in node.node_json:
            plans = node.node_json["Plans"]
            if len(plans) == 1:
                node.left = self._build_tree_recursive(plans[0], count)
            elif len(plans) == 2:
                node.left = self._build_tree_recursive(plans[0], count)
                node.right = self._build_tree_recursive(plans[1], count)

            # node.node_json["Plans"] no longer needed, empty it to save storage
            node.node_json["Plans"] = {}

        return node

    def explain_all_nodes(self, node):
        '''
        Perform depth-first traversal of the query tree to obtain
        the explanations for all of the nodes in the tree

        @param node: Current node to explain.
                     On first call of the function, node = root. 
                     Otherwise, node is either node.left or node.right
        @return: The output for the entire tree
        '''

        if node is not None:
            self.explain_all_nodes(node.left)
            self.explain_all_nodes(node.right)

            # After calling explain() on both child nodes
            # Merge their parent_dict before processing current node
            node.merge_dict()

            # Append the explanation of the node to the full string
            # And add separators to distinguish between different nodes
            self.full_output = self.full_output + node.explain(self.order) + "\n"
            if node is not self.root:
                self.full_output = (
                    self.full_output + "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n"
                )

            # Increment current node order
            self.order += 1

        return self.full_output

    def instantiate_node(self, node_json):
        '''
        Checks what is the value of node_json["Node Type"]
        
        Then, instantiate a Node subclass based on the node type

        @param node_json: The JSON / dictionary of details specific to the node
        @return: An instance of the selected subclass of Node
        '''
        match node_json["Node Type"]:
            case "Seq Scan":
                return SeqScanNode(node_json, self.login_details, self.query_details)
            case "Index Scan": 
                return IndexScanNode(node_json, self.login_details, self.query_details)
            case "Index Only Scan": 
                return IndexOnlyScanNode(node_json, self.login_details, self.query_details)
            case "Bitmap Index Scan": 
                return BitmapIndexScanNode(node_json, self.login_details, self.query_details)
            case "Bitmap Heap Scan": 
                return BitmapHeapScanNode(node_json, self.login_details, self.query_details)
            case "Bitmap And": 
                return BitmapAndNode(node_json, self.login_details, self.query_details)
            case "Bitmap Or": 
                return BitmapOrNode(node_json, self.login_details, self.query_details)
            case "CTE Scan": 
                return CTEScanNode(node_json, self.login_details, self.query_details)
            case "Subquery Scan": 
                return SubqueryScanNode(node_json, self.login_details, self.query_details)
            case "Append": 
                return AppendNode(node_json, self.login_details, self.query_details)
            case "MergeAppend": 
                return MergeAppendNode(node_json, self.login_details, self.query_details)
            case "Nested Loop Join": 
                return NestedLoopJoinNode(node_json, self.login_details, self.query_details)
            case "Merge Join": 
                return MergeJoinNode(node_json, self.login_details, self.query_details)
            case "Hash": 
                return HashNode(node_json, self.login_details, self.query_details)
            case "Hash Join": 
                return HashJoinNode(node_json, self.login_details, self.query_details)
            case "Gather": 
                return GatherNode(node_json, self.login_details, self.query_details)
            case "Gather Merge": 
                return GatherMergeNode(node_json, self.login_details, self.query_details)
            case "Sort":
                return SortNode(node_json, self.login_details, self.query_details)
            case "Incremental Sort":
                return IncrementalSortNode(node_json, self.login_details, self.query_details)
            case "Limit":
                return LimitNode(node_json, self.login_details, self.query_details)
            case "Materialize":
                return MaterializeNode(node_json, self.login_details, self.query_details)
            case "Memoize":
                return MemoizeNode(node_json, self.login_details, self.query_details)
            case "Group":
                return GroupNode(node_json, self.login_details, self.query_details)
            case "Aggregate":
                return AggregateNode(node_json, self.login_details, self.query_details)
            case "Unique":
                return UniqueNode(node_json, self.login_details, self.query_details)
            case _: 
                return Node(node_json, self.login_details, self.query_details)


class Node(object):
    """
    Represents a Node in PostgreSQL's EXPLAIN JSON output

    All nodes should inherit from this class.
    The subclasses should also replace the following attributes
    and functions with their own implementations:
    - __init__(self) to replace str_explain_formula and str_explain_difference
    - manual_cost(node_json)

    @param node_json: The JSON / dictionary of details specific to the node
    @param login_details: User-provided login details to the UI
    @param query_details: Contains the user-selected database and user-input query
    """

    def __init__(self, node_json, login_details, query_details):
        # Stores user-input details
        self.login_details = login_details
        self.query_details = query_details

        # Given formula or how formula is derived
        self.str_explain_formula = "str_explain_formula"

        # Brief explanation on the difference between formula and system calculations
        self.str_explain_difference = "str_explain_difference"

        # The JSON of this particular node
        self.node_json = node_json

        # Left and right child Node
        self.left = None
        self.right = None

        # The entire output string that will be printed by the interface.
        # This variable should ONLY be modified between when explain() is triggered
        # and when explain() is returned
        self.output = ""

        # Dict data structure to pass to parent
        self.parent_dict = None

        # Id for node for easy reference
        self.id = None

    def manual_cost(self):
        """
        Run the SQL helper functions here.
        Each SQL helper function will also append a line to the output
        This method will return the total manually calculated cost.

        @returns: An integer for the manually calculated total cost
        """
        return 0

    def explain(self, order=0):
        """
        Prepares the output for the particular node to be printed by the interface.
        Also handles clean-up after explain() is executed successfully

        @type order : int
        @param order : The order in which this Node is being explained, relative
                       to the entire query tree
        """

        # Reset the output just in case
        self.output = ""

        # Briefly introduce the node with the name of the Node Type
        self.append(str(order) + ". " + self.node_json["Node Type"] + " (#" + str(self.id) + ")")
        self.append()

        # Append the formula explanation
        self.append(self.str_explain_formula)
        calculated_cost = self.manual_cost()

        # Append the calculated cost
        self.append("Calculated Cost: " + str(calculated_cost))
        self.append()

        # Append the PostgreSQL total cost
        self.append(
            "PostgreSQL Total Cost: " + str(self.node_json.get("Total Cost", "Unknown"))
        )

        # Compare the calculated cost with PostgreSQL's total cost
        if calculated_cost == self.node_json.get("Total Cost"):
            self.append(
                "Manually calculated cost is the same as system calculated cost."
            )
        else:
            self.append(
                "Manually calculated cost is different from system calculated cost."
            )
            self.append()
            self.append("Reason for difference:")
            self.append(self.str_explain_difference)

        # This node has been explained once
        # Build a dict to pass to parent to mark this Node as explained
        self.parent_dict = self.build_parent_dict()

        return self.output

    def build_parent_dict(self):
        """
        Builds a dict of specific values to pass to the parent Node for their
        calculations. Only includes necessary attributes.
        """
        parent_dict = {
            # Node type of current node
            "Node Type": "Placeholder",

            # Estimated number of blocks for the intermediate relation
            # resulting from this node
            "block_size": 0,

            # Estimated number of tuples for the intermediate relation
            # resulting from this node
            "tuple_size": 0,

            # Manually calculated cost of executing this node
            "manual_cost": 0,

            # Given Total Cost by Postgres from executing this node
            "postgre_cost": 0
        }

        return parent_dict
        # attr: self.node_json[attr] for attr in attributes if attr in self.node_json

    def merge_dict(self):
        """
        Obtains the dictionary created by the left and right childs if any
        Then, label the dict to each child, and merge the two dictionaries
        with the JSON provided by PostgreSQL into one big dictionary.
        """
        if self.left is not None:
            for key, value in self.left.parent_dict.items():
                self.node_json["Left " + key] = value
        if self.right is not None:
            for key, value in self.right.parent_dict.items():
                self.node_json["Right " + key] = value

    def append(self, tgt: str = "", src: str = "output", eol: str = '\n'):
        '''
        Append a string to the end of the selected string.
        If no src is specified, then append to Node.output
        If no tgt is specified, then the behaviour is similar to print(),
        which is to add an empty line to the output
        If no eol is specified, a newline character will be added after each string.

        @param tgt: The string to append to at the end of the source string
        @param src: Specifies which string to append the target string to.
                    If append to self.str_explain_formula, src = "formula"
                    If append to self.str_explain_difference, src = "difference"
                    Otherwise, append to self.output
        @param eol: End-of-line. Append additionally this character or string to the end of the target string
        '''

        match src:
            case "formula":
                self.str_explain_formula = self.str_explain_formula + tgt + eol
            case "difference":
                self.str_explain_difference = self.str_explain_difference + tgt + eol
            case _:
                self.output = self.output + tgt + eol

    ######### Functions that Re-queries the Database #########

    def B(self, relation: str, show: bool = True):
        """
        Return number of blocks for the specified relation

        @param relation : The relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT pg_relation_size('{rel}') / current_setting('block_size')::int AS num_blocks
        '''.format(rel = relation)

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_blocks = result[0][0]

        if show: 
            self.append("Number of blocks for relation '" + relation + "': " + str(num_blocks))
        return num_blocks

    def T(self, relation: str, show: bool = True):
        """
        Return number of tuples for the specified relation

        @param relation : The relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT COUNT(*) as num_tuples FROM {rel}
        '''.format(rel = relation)

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_tuples = result[0][0]

        if show: 
            self.append("Number of tuples for relation '" + relation + "': " + str(num_tuples))
        return num_tuples

    def M(self, show: bool = True):
        """
        Return buffer size allocated to DBMS in memory

        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT setting FROM pg_settings WHERE name = 'shared_buffers';
        '''

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        buffer_size = int(result[0][0])

        if show: 
            self.append("Buffer size: " + str(buffer_size))
        return buffer_size

    def V(self, relation: str, attribute: str, show: bool = True):
        """
        Return number of unique values for the attribute in
        the provided relation

        @param relation : The relation to query
        @param attribute : The attribute of the relation to query
        @param show : Whether to print out the results of the query
        """

        # Prepare the query
        query_details = QueryDetails
        query_details.database = self.query_details.database
        query_details.query = '''
        SELECT COUNT(DISTINCT {attr}) AS num_unique_values FROM {rel};
        '''.format(attr = attribute, rel = relation)

        # Execute and retrieve the values
        result = retrieve_query(self.login_details, query_details, False)
        num_unique = result[0][0]

        if show: 
            self.append(
                "Number of unique values for attribute '" +
                attribute +
                "' of relation '" +
                relation +
                "': " +
                str(num_unique)
            )
        return num_unique


#################### NODE SUBCLASSES ######################


class MyNode(Node):
    '''
    Testing node. Will print all of B(), T(), V() and M
    '''
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "Formula: B(rel) + T(rel) + V(rel, attr) + M"
        self.str_explain_difference = "Some explanation for difference"

    def manual_cost(self):
        rel = "nation"
        attr = "n_name"
        return self.B(rel) + self.T(rel) + self.V(rel, attr) + self.M()
    
    def build_parent_dict(self):
        rel = "nation"

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": 10,
            "postgre_cost": self.node_json["Total Cost"]
        }

        return parent_dict

class ScanNodes(Node):
    '''
    Helper class that contains utility functions for most scan-related nodes
    '''
    def cardinality(self, is_tuple):
        '''
        Estimate number of filtered tuple resulting from this query node

        @param is_tuple: True if returning number of tuples. False if returning number of blocks
        '''
        rel = self.node_json["Relation Name"]
        attr = self.retrieve_attribute_from_filter(self.node_json["Filter"])
        num_blocks = self.B(rel, False)
        num_tuples = self.T(rel, False)
        num_unique = self.V(rel, attr, False)
        
        # Three different cases
        if "Filter" not in self.node_json:
            # Case 1: Retrieve entire table. Selectivity = 1
            return num_tuples if is_tuple else num_blocks

        elif ">" in self.node_json["Filter"] or "<" in self.node_json["Filter"]:
            # Case 2: Retrieve a range of records. Selectivity = 1/3
            return num_tuples / 3 if is_tuple else num_blocks / 3

        else:
            # Case 3: Retrieve one exact record. Selectivity = V(R, a)
            if num_unique == 0:
                return 0
            return num_tuples / num_unique if is_tuple else num_blocks / num_unique

    def retrieve_attribute_from_filter(self):
        '''
        Pass in the value from node_json["Filter"] or node_json["Index Cond"] and return the attribute
        Example filter = "(o_custkey < 1000000)"
        '''

        # Retrieve the filter from node_json
        if "Filter" in self.node_json:
            filter = self.node_json["Filter"]
        elif "Index Cond" in self.node_json:
            filter = self.node_json["Index Cond"]
        else:
            return

        # Define the comparison operators
        comparison_operators = ["<", ">", "="]

        # Find the index of the first appearance of any comparison operator
        index = min(filter.find(op) for op in comparison_operators if op in filter)

        # Extract the text before the comparison operator
        attr = filter[1:index].strip()

        return attr
    
    def build_parent_dict(self):
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.cardinality(False),
            "tuple_size": self.cardinality(True),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"]
        }

        return parent_dict


class SeqScanNode(ScanNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        self.append(src = "formula", tgt = "Sequential scan on relation '" + rel + "'")
        self.append(src = "formula", tgt = "Cost Formula: B(" + rel + ")")

        # Explain the difference
        self.append(src = "difference", tgt = "PostgreSQL estimates the selectivity more accurately.")
        self.append(src = "difference", tgt = "PostgreSQL factors in parallel processing and CPU cost into the calculation")

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.B(rel)
    
    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        parent_dict["manual_cost"] = self.B(rel, False)

        return parent_dict


class IndexScanNode(ScanNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        self.append(src = "formula", tgt = "Index on attribute '" + attr + "' of relation '" + rel + "'")
        self.append(src = "formula", tgt = "Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")")

        # Explain the difference
        self.append(src = "difference", tgt = "PostgreSQL uses the more accurate Market and Lohman approximation to estimate number of pages fetched.")
        self.append(src = "difference", tgt = "Also, PostgreSQL uses optimizations such as parallel processing and caching.")
        self.append(src = "difference", tgt = "These will either reduce cost or makes cost computation more accurate.")

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        return self.T(rel) / self.V(rel, attr)
    
    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class IndexOnlyScanNode(ScanNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute 
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        self.append(src = "formula", tgt = "Index on attribute '" + attr + "' of relation '" + rel + "'")
        self.append(src = "formula", tgt = "Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")")

        # Explain the difference
        self.str_explain_difference = """Index Only Scan differs from Index Scan in that PostgreSQL only needs to access the index blocks as all of the values required are in the index.
        PostgreSQL uses methods to reduce the cost as a result of not requiring to access heap storage.
        """

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        return self.T(rel) / self.V(rel, attr)
    
    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class BitmapIndexScanNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        self.str_explain_formula = "As PostgreSQL does not access the data blocks, the cost is negligible"
        self.str_explain_difference = '''PostgreSQL factors in the cost of accessing the index blocks of the relation'''

    def manual_cost(self):
        return 0
    
    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.B(rel, False),
            "tuple_size": self.T(rel, False),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"]
        }

        return parent_dict


class BitmapHeapScanNode(ScanNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = ""
        self.str_explain_difference = ""

        # Explain the relation, attribute 
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        self.append(src = "formula", tgt = "Accessing the heap through index on attribute '" + attr + "' of relation '" + rel + "'")
        self.append(src = "formula", tgt = "Cost Formula: T(" + rel + ") / V(" + rel + ", " + attr + ")")

        # Explain the difference
        self.str_explain_difference = """PostgreSQL factors in overhead of bitmap access into cost calculation
        """

    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        return self.T(rel) / self.V(rel, attr)
    
    def build_parent_dict(self):
        # All other values are unchanged
        parent_dict = super().build_parent_dict()

        # Except for manual_cost
        rel = self.node_json["Relation Name"]
        attr = super().retrieve_attribute_from_filter()
        parent_dict["manual_cost"] = self.T(rel, False) / self.V(rel, attr, False)

        return parent_dict


class BitmapAndNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "AND operation on bit arrays are negligible"
        self.str_explain_difference = '''PostgreSQL factors in overhead of bitmap access into cost calculation'''

    def manual_cost(self):
        return 0
    
    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        # Treat this as an intersect operator unless there is more time
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": min(self.node_json["Left block_size"], self.node_json["Right block_size"]),
            "tuple_size": min(self.node_json["Left tuple_size"], self.node_json["Right tuple_size"]),
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"]
        }

        return parent_dict


class BitmapOrNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "OR operation on bit arrays are negligible"
        self.str_explain_difference = """PostgreSQL factors in overhead of bitmap access into cost calculation
        """

    def manual_cost(self):
        return 0
    
    def build_parent_dict(self):
        rel = self.node_json["Relation Name"]

        # Treat this as a union operator unless there is more time
        parent_dict = {
            "Node Type": self.node_json["Node Type"],
            "block_size": self.node_json["Left block_size"] + self.node_json["Right block_size"],
            "tuple_size": self.node_json["Left tuple_size"] + self.node_json["Right tuple_size"],
            "manual_cost": 0,
            "postgre_cost": self.node_json["Total Cost"]
        }

        return parent_dict


class CTEScanNode(SeqScanNode):
    """
    CTE Scan is very similar to sequential scan, but for WITH operations
    """

    pass

class SubqueryScanNode(SeqScanNode):
    '''
    Subquery Scan is very similar to sequential scan, but for nested SELECT operations
    '''
    pass

class AppendNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combine the results of the child operations.
        Cost Formula: SIGMA(Cost(Child))
        """

        # Explain the difference
        self.str_explain_difference = """PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions.
        """

    def manual_cost(self):

        total_cost = (
            self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        )

        return total_cost


class MergeAppendNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the sorted results of the child operations, in a way that preserves their sort order.
        Cost Formula: SIGMA(Cost(Child)) + Merge_Cost
        """

        # Explain the difference
        self.str_explain_difference = """MergeAppend of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream.  If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top entry.
        """

    def manual_cost(self):
        total_cost = (
            self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        )

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = (
            self.node_json["Left tuple_size"] + self.node_json["Right tuple_size"]
        )
        total_cost += merge_cost

        return total_cost


class NestedLoopJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """An implementation of join or lookup where the first child node is run once, then for every row it produces, its partner is looked up in the second node.
        Cost Formula: min(B({R}), B({S})) + (B({R}) * B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """The cost estimation in PostgreSQL sums up the startup cost, total cost of both outer and inner path, and also the rescan cost of the inner path. However, the approach is different and not by using block size, but instead it takes the cost of the path.
        """

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return min(R_block_size, S_block_size) + (R_block_size * S_block_size)


class MergeJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """An implementation of join which is possible when the two lists of rows to be joined are already sorted on their join keys.
        Cost Formula: 3(B({R}) + B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """ PostgreSQL's cost estimation is more comprehensive, accounting for sorting costs, actual data size and distribution, and system factors like disk I/O, CPU usage, and caching effects, leading to a more accurate and context-sensitive prediction.
        """

    def manual_cost(self):

        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size + S_block_size)


class HashNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        rel = self.node_json["Left Node Type"]

        args = {"rel": rel}
        # self.str_explain_formula = """Hashes the query rows for use by its parent operation, usually used to perform a JOIN.'
        # Cost Formula: Total_Cost = Scan_Cost + Hash_Build_Cost (Assume T({rel}) here for now.)
        # """.format(
        #     args
        # )

        self.str_explain_formula = """Hashes the query rows for use by its parent operation, usually used to perform a JOIN.'
        We assume the cost are calculated in the hash join node, thus ignore the cost here.
        """

        # Explain the difference
        self.str_explain_difference = """We assume the cost are calculated in the hash join node, thus ignore the cost here. In PostgreSQL, the cost is calculated for the whole hash join process using two versions of estimation function, no separate calculation for hash nodes.
        """

    def manual_cost(self):

        # return self.node_json["Left tuple_size"]

        return 0


class HashJoinNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        rel_R = self.node_json["Left Node Type"]
        rel_S = self.node_json["Right Node Type"]

        args = {"R": rel_R, "S": rel_S}
        self.str_explain_formula = """A hash join operation between two relations, where the first relation '{rel_R}' is used to build the hash table, and the second relation '{rel_S}' is then probed against this hash table.'
        Cost Formula: 3(B({R}) + B({S}))
        """.format(
            args
        )

        # Explain the difference
        self.str_explain_difference = """Our implementation here follows the Grace hash join calculation.
        PostgreSQL does not use the Grace hash join algorithm. 
        Instead, it implements a variant of the hash join that is optimized for in-memory operations but can also handle larger-than-memory datasets by spilling to disk.
        """

    def manual_cost(self):
        R_block_size = self.node_json["Left block_size"]
        S_block_size = self.node_json["Right block_size"]

        return 3 * (R_block_size * S_block_size)


class GatherNode(Node): # formula unsure
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the output of child nodes, which are executed by parallel workers.
        Cost Formula: SIGMA(Cost(Child))
        """

        # Explain the difference
        self.str_explain_difference = """PostgreSQL's implementation of cost calculation takes the sum of startup cost and run cost of subpath operations, which is much more complex when compared to our assumptions. Parallel setup  and communication cost are also taken into consideration.
        """

    def manual_cost(self):
        total_cost = 0
        for child in self.node_json["ChildNodes"]:
            total_cost += child.manual_cost()
        return total_cost


class GatherMergeNode(Node): # formula unsure
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)

        # Explain the relation, attribute
        self.str_explain_formula = """Combines the output of child nodes, which are executed by parallel workers. Gather Merge consumes sorted data, and preserves this sort order.
        Cost Formula: SIGMA(Cost(Child)) + Merge_Cost
        """

        # Explain the difference
        self.str_explain_difference = """GatherMerge of PostgreSQL merges several pre-sorted input streams, using a heap that at any given instant holds the next tuple from each stream. If there are N streams, we need about N*log2(N) tuple comparisons to construct the heap at startup, and then for each output tuple, about log2(N) comparisons to replace the top heap entry with the next tuple from the same stream. Parallel setup  and communication cost are also taken into consideration.
        """

    def manual_cost(self):
        total_cost = (
            self.node_json["Left manual_cost"] + self.node_json["Right manual_cost"]
        )

        # Merge cost might be proportional to the total number of rows across all children
        # Assuming a linear merge cost model here
        merge_cost = (
            self.node_json["Left tuple_size"] + self.node_json["Right tuple_size"]
        )
        total_cost += merge_cost

        return total_cost


class SortNodes(Node):
    def extract_relation_name(self):
        '''
        Retrieve the name of the relation from node_json["Sort Key"]
        '''

        # Retrieve the value from node_json
        sort_key = self.node_json["Sort Key"][0]

        # Split the sort key string by dot (.) to separate the relation name
        parts = sort_key.split('.')
        if len(parts) > 1:
            # Return the first part as the relation name
            return parts[0]
        else:
            # If the sort key does not contain a dot, return None
            return None


class SortNode(SortNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        #explain relation and attributes
 
        if (self.node_json["Sort Method"] == "external merge"):
            self.str_explain_formula = "Mergesort Formula : 3 * B(rel). Mergesort used when data does not fit in memory(work_mem).Plan width * T(R) > work_mem"
            self.str_explain_difference = '''PostgreSQL includes default cost per comparison costs overhead per extracted tuple
            '''
 
        elif(self.node_json["Sort Method"] == "quicksort"):
            self.str_explain_formula = "Quicksort Formula : B(rel). Default algorithm,Quicksort used when entire data fits into memory(work_mem) -- One pass.Plan width * T(R) < work_mem"
            self.str_explain_difference = '''PostgreSQL includes default cost per comparison costs overhead per extracted tuple
                '''
        elif(self.node_json["Sort Method"] == "top-N heapsort"):
            self.str_explain_formula = "Top-N heapsort Formula : B(rel) / 3. Top-N heapsort is used when only a limited amount of data is required, such as when theres LIMIT after order."
            self.str_explain_difference = '''PostgreSQL includes default cost per comparison costs overhead per extracted tuple, as well as cost to maintain heap of the top  N items.
                '''
    
    def manual_cost(self):
        rel = super().extract_relation_name()
        if (self.node_json["Sort Method"] == "external merge"):
            return self.B(rel) * 3
        
        elif(self.node_json["Sort Method"] == "quicksort"):
            return self.B(rel)
        
        elif(self.node_json["Sort Method"] == "top-N heapsort"):
            #Not sure about topn cost
            return self.B(rel)
 
class IncrementalSortNode(SortNodes):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        #explain relation and attributes
        self.str_explain_formula = "Formula : B(rel) - Estimated Sorted Blocks. Incremental Sort is used when input data is partially ordered"
        self.str_explain_difference = '''Postgresql uses different calculations to calculate number of  groups with equal presorted keys. There are also overhead costs in detecting sort groups and additional costs for each 
                                    input group. '''
    
    def manual_cost(self):
        rel = super().extract_relation_name()
        return self.B(rel)/3 
        
class LimitNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        #explain relation and attributes
        self.str_explain_formula = "Formula : B(rel) * "
        self.str_explain_difference = '''Explain '''
 
    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.B(rel)
 
class MaterializeNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        #explain relation and attributes
        self.str_explain_formula = "Maeterialize Formula : T(rel) * 2. Materialize used to store intermediate results temporarily to improve the efficiency"
        self.str_explain_difference = '''PostgreSQL includes cpu operator costs per tuple to reflect bookkeeping overhead, and accounts if volume of data to materialize spills and exceed work_mem and needs to 
                                         be written to disk(higher cost) '''
 
    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        return self.T(rel) * 2
 

class MemoizeNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        #explain relation and attributes
        self.str_explain_formula = "Memoize used to cache and reuse results of expensive operations when they are executed with the same parameters multiple times in a query."
 
        self.str_explain_difference = '''Costs of a memoize node dependent also on nature of operations and frequency, cache hit rate and lookup times  '''
 
    def manual_cost(self):
        return 0
        
class GroupNode(Node):
    
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "Formula : T(rel) * Number of Group Columns. "
        self.str_explain_difference = '''PostgreSQL includes default cost per comparison costs overhead per input tuple.  '''
    
 
    def manual_cost(self):
        #test if can
        rel = self.node_json["Relation Name"]
        numGroupCol = len(self.node_json.get("Group Key", []))
        return self.T(rel) * numGroupCol
 
class AggregateNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        
        if (self.node_json["Strategy"] == "Sorted" or self.node_json["Strategy"] == "Mixed"):
            self.str_explain_formula = "Formula : T(rel) * Number of groups.Aggregate used to compute summaries from sets of values like SUM,AVG. "
            self.str_explain_difference = '''PostgreSQL has different aggregate strategies depending on the input.  '''
 
        #assume T(rel) as cost
        elif (self.node_json["Strategy"] == "Hased"):
            self.str_explain_formula = "Formula : T(rel).Aggregate hash strategy used over all rows when there is no group by"
            self.str_explain_difference = '''Aggregate Hash costs include computing hash value and retiving from hash table, and cost due to chance of tuple spilling.  '''
        
        #default, Agg strategy is plain
        else:
            self.str_explain_formula = "Formula : T(rel).Aggregate plain strategy used over all rows when there is no group by, no need for grouping before aggregation"
            self.str_explain_difference = '''PostgreSQL includes default cost per comparison costs overhead per input tuple.  '''
        
    def manual_cost(self):
        rel = self.node_json["Relation Name"]
        if (self.node_json["Strategy"] == "Sorted" or self.node_json["Strategy"] == "Mixed"):
            numGroupCol = len(self.node_json.get("Group Key", []))
            return self.T(rel) * numGroupCol
        
        else:
            return self.T(rel)
        
class UniqueNode(Node):
    def __init__(self, node_json, login_details, query_details):
        super().__init__(node_json, login_details, query_details)
        self.str_explain_formula = "Remove duplicates from sorted set"
 
    def manual_cost(self):
        return 0
